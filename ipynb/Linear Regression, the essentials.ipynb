{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hello Folks! Welcome back and happy new year as this is the first post in 2023 and certainly not the last. In this post I will discuss about Linear Regression which is one of the wildly used Machine Learning model to predict a continious variables (a fancy terms to say that we are predicting a number, also refered to as numerical target or label). The model is quite simple to understand yet powerful and is used mainly when interpretability of the model (when we want to know which dependent variables aka features are the most predictive) is required like in the consumer lending or medical fields where transparency is at its core."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have briefly discussed about linear regression in [this](https://semasuka.github.io/blog/2021/04/04/demystify-machine-learning.html) post, where we debunking the myth \"Does money buys happiness?\" (spoiler alert, we found out that it actually does) using a simple linear regression model. In this post we will diver deeper, and discuss the main ideas about linear regression like sum square root (SSR), mean square error (MSE), R-square, touch a little bit on derivate and gradient descent in regards to linear regression (model optimization) and finally introduce the p-value at the end. Of course, we will demonstrate all these with code in Python. You know the drill by now! let's get started!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. What the heck is a linear regression? and where does it comes from?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Definition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is part of linear model family(which assume a linear relationship between the dependent and independent variables) which comprised of Logistic Regression (will have a post on this model very soon), Poisson Regression, Probit Regression, Linear Discriminant Analysis (LDA), Cox Proportional Hazards Regression. The goal of a linear regression is to fit a line (using the best parameter, the slope \"m\" of a straight line in this case) to the data that minimizes the loss function or cost function (the difference between the predicted output of a machine learning model and the actual output). The loss function helps us to measure how well the model is performing given a dataset. The lower the loss function is, the better the model is performing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Brief history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression has a long history, dating back to the 18th century when it was first introduced by mathematician Pierre-Simon Laplace. In the 19th century, Augustin Louis Cauchy and Carl Friedrich Gauss (yes the one who invented the gaussian distribution aka normal distribution) made important contributions to the development of linear regression. In the 20th century, statistician Ronald A. Fisher developed a method for finding the line of best fit using maximum likelihood, which is still widely used today."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Over time, linear regression has been extended and modified to handle more complex relationships between variables, such as polynomial regression, logistic regression, and others. Despite its simplicity, linear regression remains a widely used method for understanding and making predictions about the relationships between variables."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Illustration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a simple example to illustrate to understand linear regression, let's say you are the president economic advisor of your country. The country is rumored to be on the blink of an imminent recession from what the economist are saying and the R word is on every mouth on the media but surprisingly the unemployment number looks low. Now the president ask you: \"what is the correlation (mutual relationship) between the unemployment rate and the consumer spending since we know that consumer spending constitute 70% of our GDP?\". He remembers correctly from his economic class he took in university, that as the employment rate increases, we should expect consumer spending to increase as well, as more people are employed and have more money to spend we should not fear a recession. So he is confused and needs some clarification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a data nerd, you always know that the best way to answer his question is with numbers and you know what they say right? the numbers don't lie. so you decide to gather all the unemployment data and consumer spending data and start to investigate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For illustration purposes you decide to just sample the data of 5 random cities in your country."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![unemployment_vs_consumer_spending](/blog/assets/post_cont_image/unemployment_spending.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0b79941bf6abfa97c11cce899e2bfe6606585cc2329e00a10bb8e91ee8e76a75"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
